# Socinx AI Service

A FastAPI-based AI service providing text embeddings and image captioning capabilities using transformer models.

## Overview

This service provides two main AI functionalities:
- **Text Embeddings**: Generate semantic embeddings for text using sentence transformers
- **Image Captioning**: Generate descriptive captions for images using BLIP models

## Features

- üöÄ Fast and efficient API built with FastAPI
- ü§ñ GPU acceleration support (CUDA-enabled)
- üì¶ Docker containerization for easy deployment
- üîÑ Automatic model loading on startup
- üåê RESTful endpoints for embeddings and image captioning

## Requirements

- Python 3.10+
- CUDA 11.8+ (optional, for GPU acceleration)
- Docker (for containerized deployment)

## Setup

### Local Development

1. **Create a virtual environment**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the server**:
   ```bash
   uvicorn app:app --reload --host 0.0.0.0 --port 7860
   ```

The API will be available at `http://localhost:7860`

### Docker Deployment

1. **Build the image**:
   ```bash
   docker build -t socinx-ai-service .
   ```

2. **Run the container**:
   ```bash
   docker run -p 7860:7860 socinx-ai-service
   ```

## API Endpoints

### Text Embeddings
- **POST** `/embed/text` - Generate text embeddings
  - Input: `text` (string or list of strings, max 5000 chars)
  - Output: 768-dimensional normalized embeddings using cosine similarity
  - Model: `sentence-transformers/all-mpnet-base-v2`

### Image Captioning
- **POST** `/caption/image` - Generate image caption from URL
  - Input: `image_url` (valid image URL)
  - Output: Natural language caption generated by BLIP
  - Model: `Salesforce/blip-image-captioning-base`

### Health Check
- **GET** `/` - Health check endpoint
  - Returns service status

### Interactive Documentation
- Swagger UI: `http://localhost:7860/docs`
- ReDoc: `http://localhost:7860/redoc`

## Models Used

- **Text Embeddings**: `sentence-transformers/all-mpnet-base-v2`
- **Image Captioning**: `Salesforce/blip-image-captioning-base`

Models are automatically downloaded on first startup. Downloaded models are cached to `hf_cache/` for faster subsequent loads.

## Project Structure

```
server/
‚îú‚îÄ‚îÄ app.py              # Main FastAPI application
‚îú‚îÄ‚îÄ requirements.txt    # Python dependencies
‚îú‚îÄ‚îÄ Dockerfile          # Docker configuration
‚îî‚îÄ‚îÄ README.md           # This file
```

## Performance Notes

- First run will download ~2GB of model weights
- GPU acceleration (CUDA) significantly improves performance
- Models are cached locally for faster subsequent starts
- Supports batch processing for text embeddings

## Supported Models

- **Text Embedding Model**: `all-mpnet-base-v2`
  - Dimension: 768
  - Type: Semantic embeddings for text
  
- **Image Caption Model**: BLIP (Base version)
  - Generates descriptive captions for images
  - Max tokens per caption: 50
  - Beam search: 3 beams

## License

[Add your license here]

## Support

For issues or questions, refer to the API documentation at `/docs` or `/redoc`.
